{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
   "<div style=\"text-align: center;\">\r\n",
    "    <img src=\"https://user-images.githubusercontent.com/86345471/221379942-51f24819-1f76-4289-8dee-06ea69f730f6.png\" alt=Main \"KPI />\r\n",
    "</d></br>\r\n",
    "Pr №2 — Зниження розмірності, кластеризація та текстова класифікація\n",
    "\n",
    "## Завдання:\n",
    "1. **PCA + t-SNE** — зниження розмірності та порівняння якості класифікації\n",
    "2. **K-means quantization** — кластерний аналіз зображення\n",
    "3. **Text classification** — обробка, візуалізація та класифікація текстів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print('✅ Бібліотеки імпортовано успішно!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣ Зниження розмірності (PCA + t-SNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Завантаження того ж датасету, що в ЛР1 ===\n",
    "df = pd.read_csv('global_population.csv')\n",
    "\n",
    "# Знаходимо колонку з Population\n",
    "for col in df.columns:\n",
    "    if 'Population(' in col:\n",
    "        target_feature = col\n",
    "        break\n",
    "\n",
    "# Створюємо цільову змінну (класи за чисельністю населення)\n",
    "bins = [-1, df[target_feature].quantile(0.33), df[target_feature].quantile(0.66), df[target_feature].max()]\n",
    "labels = ['low', 'medium', 'high']\n",
    "df['class'] = pd.cut(df[target_feature], bins=bins, labels=labels)\n",
    "\n",
    "# Формуємо X, y\n",
    "drop_cols = ['Country', 'class']\n",
    "X = df.drop(columns=drop_cols)\n",
    "y = df['class']\n",
    "y_enc = LabelEncoder().fit_transform(y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Тренуємо модель до PCA\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_enc, test_size=0.3, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "acc_before = accuracy_score(y_test, y_pred)\n",
    "print('Точність ДО PCA:', round(acc_before,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PCA ===\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print('Відсоток дисперсії, пояснений двома компонентами:', pca.explained_variance_ratio_)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=df['class'], palette='Set1')\n",
    "plt.title('PCA — 2 компоненти')\n",
    "plt.show()\n",
    "\n",
    "# Класифікація після PCA\n",
    "X_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca, y_enc, test_size=0.3, random_state=42)\n",
    "clf.fit(X_train_pca, y_train)\n",
    "y_pred_pca = clf.predict(X_test_pca)\n",
    "acc_after_pca = accuracy_score(y_test, y_pred_pca)\n",
    "print('Точність ПІСЛЯ PCA:', round(acc_after_pca,3))\n",
    "\n",
    "print('\\n✅ Висновок: PCA зменшує вимірність, пришвидшує навчання, але може трохи знизити точність.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === t-SNE ===\n",
    "tsne = TSNE(n_components=2, perplexity=10, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=X_tsne[:,0], y=X_tsne[:,1], hue=df['class'], palette='Set2')\n",
    "plt.title('t-SNE — візуалізація у 2D')\n",
    "plt.show()\n",
    "\n",
    "print('✅ t-SNE показує локальні кластери, але не зберігає глобальну структуру.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2️⃣ Кластерний аналіз — K-Means Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from PIL import Image\n",
    "\n",
    "img = Image.open('image.jpg')  # Заміни на своє зображення у тій самій папці\n",
    "img = img.resize((200,200))\n",
    "data = np.array(img) / 255.0\n",
    "pixels = data.reshape(-1, 3)\n",
    "\n",
    "levels = [64, 32, 16, 8]\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "for i, n_colors in enumerate(levels):\n",
    "    kmeans = KMeans(n_clusters=n_colors, random_state=42)\n",
    "    labels = kmeans.fit_predict(pixels)\n",
    "    new_colors = kmeans.cluster_centers_[labels]\n",
    "    quantized = new_colors.reshape(data.shape)\n",
    "    plt.subplot(1, len(levels), i+1)\n",
    "    plt.imshow(quantized)\n",
    "    plt.title(f'{n_colors} colors')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle('K-Means Color Quantization')\n",
    "plt.show()\n",
    "\n",
    "print('✅ Зменшення кількості кольорів пришвидшує обробку, але втрачає деталі.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3️⃣ Обробка та класифікація текстових даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.utils import resample\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Використаємо невеликий текстовий датасет (дві категорії)\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/dD2405/Twitter_Sentiment_Analysis/master/train.csv')\n",
    "data = data[['label','tweet']].rename(columns={'tweet':'text'})\n",
    "data = data[data['label'].isin([0,1])].sample(2000, random_state=42)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z ]', '', text)\n",
    "    text = text.lower()\n",
    "    words = [w for w in text.split() if w not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "data['clean'] = data['text'].apply(clean_text)\n",
    "\n",
    "# WordCloud для кожного класу\n",
    "for label in data['label'].unique():\n",
    "    text = ' '.join(data[data['label']==label]['clean'])\n",
    "    wc = WordCloud(width=500, height=300, background_color='white').generate(text)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'WordCloud for class {label}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TF-IDF + Naive Bayes класифікація ===\n",
    "\n",
    "# Балансування класів\n",
    "majority = data[data.label == 0]\n",
    "minority = data[data.label == 1]\n",
    "minority_upsampled = resample(minority, replace=True, n_samples=len(majority), random_state=42)\n",
    "data_balanced = pd.concat([majority, minority_upsampled])\n",
    "\n",
    "print('Баланс класів:')\n",
    "print(data_balanced['label'].value_counts())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_balanced['clean'], data_balanced['label'], test_size=0.3, random_state=42)\n",
    "\n",
    "model = make_pipeline(TfidfVectorizer(max_features=2000), MultinomialNB())\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy:', round(accuracy_score(y_test, y_pred),3))\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
